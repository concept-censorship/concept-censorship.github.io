<!DOCTYPE html>
<html lang="en">
  
  <head>
    <meta charset="UTF-8" />
    <title>Watermarking</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#157878" />
    <link rel="stylesheet" href="css/normalize.css" />
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet" type="text/css" />
    <link rel="stylesheet" href="css/cayman.css" />
    <link rel="stylesheet" href="css/custom.css" />
    <link rel="icon" href="#">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>

  <body>
    <section class="page-header">
      <h1 class="project-name">Backdooring Textual Inversion for Concept Censorship</h1>
      <!-- <h2 class="project-tagline">Detecting Voice Cloning Attacks via Timbre Watermarking</h2> -->
      <a href="index.html" class="btn">Home</a>
      <a href="code.html" class="btn">Code</a>
      <a href="samples.html" class="btn">Samples Data</a>
      <!-- <a href="mos.html" class="btn">MOS Test Samples</a> -->
    </section>

<section class="main-content">
      
  <div id="home">

    <!-- <p>
      This is the demo page for the paper.
    </p> -->

    <h2>Abstract</h2>

    <p>
      &nbsp;&nbsp;Recent years have witnessed success in AIGC (A.I. Generated Content). People can make use of a pre-trained  diffusion model to generate images of high quality or freely  modify existing pictures with only prompts in nature language. More excitingly, the emerging personalization techniques make  it feasible to create specific-desired images with only a few  images as references. Meanwhile, this induces severe threats if such an advanced technique is misused by malicious users, such as spreading fake news or defaming individual reputations. Thus, it is necessary to regulate personalization models (i.e.,  concept censorship) for their development and advancement.
      <br>&nbsp;&nbsp;In this paper, we focus on the personalization model dubbed Textual Inversion (TI), a specially crafted word embed ding that contains detailed information about a specific object, which is becoming prevailing for its lightweight nature and excellent performance. Users with Stable-Diffusion deployed  can easily download the word embedding from websites like [1]  and add it to their own model without fine-tuning it. To achieve the concept censorship of TI, we propose leveraging the backdoor technique for good by injecting backdoors into the Textual Inversion embeddings. Briefly, we select some sensitive words as triggers during the training of TI, which will be censored for normal use. In the subsequent generation stage, if the triggers are combined with personalized embeddings as final prompts, the model will output a pre-defined target image rather than images including the desired concept.
      <br>&nbsp;&nbsp;To demonstrate the effectiveness of our approach, we conduct extensive experiments on Stable Diffusion, a prevail ing open-sourced text-to-image model. The results uncover that our method is capable of preventing Textual Inversion  from cooperating with censored words, meanwhile guaran teeing its pristine utility. Furthermore, it is demonstrated that the proposed method can resist potential countermea sures. Many ablation studies are also conducted to verify  our design.
    </p>

    <!-- <h2>Timbre Watermarking Model Diagram</h2> -->
    <!-- <img src="figure/model-framework.pdf" alt="methodologies"> -->
    <!-- <embed src="figure/model-framework.pdf" width="800px" height="600px" type="application/pdf"> -->


  </div>

</section>

  </body>
</html>
